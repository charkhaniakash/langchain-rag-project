# LangChain RAG Project - Complete Implementation

A full-featured Retrieval-Augmented Generation (RAG) system built with LangChain, using only free tools and APIs.

## ğŸŒŸ Features

- **Document Loading**: Automatically loads and processes text documents
- **Smart Chunking**: Intelligently splits documents for optimal retrieval
- **Semantic Search**: Uses embeddings for meaning-based search (not just keywords)
- **Free LLM**: Powered by Groq's fast, free API
- **Local Vector DB**: ChromaDB runs entirely on your machine
- **Source Tracking**: See which documents were used for each answer
- **Evaluation Tools**: Measure and improve system performance
- **Interactive & Demo Modes**: Multiple ways to use the system

## ğŸ› ï¸ Technology Stack

- **Framework**: LangChain 0.1.0
- **LLM**: Groq API (Mixtral-8x7b) - Free
- **Embeddings**: sentence-transformers (all-MiniLM-L6-v2) - Local, free
- **Vector Store**: ChromaDB - Local, free
- **Language**: Python 3.8+

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)
- Groq API key (free from https://console.groq.com/)

### Step-by-step Setup

1. **Clone or download this project**
```bash
   cd langchain-rag-project
```

2. **Create virtual environment**
```bash
   python -m venv venv
   
   # Activate it:
   # Windows:
   venv\Scripts\activate
   # macOS/Linux:
   source venv/bin/activate
```

3. **Install dependencies**
```bash
   pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
   # Copy the example file
   cp .env.example .env
   
   # Edit .env and add your Groq API key
   # Get free key at: https://console.groq.com/
```

5. **Add your documents**
```bash
   # Place your .txt files in:
   data/sample_docs/
   
   # Sample documents are already included!
```

## ğŸš€ Usage

### Quick Start
```bash
python main.py
```

Then select your preferred mode:
- **Interactive Q&A**: Ask questions in real-time
- **Demo Mode**: See example questions and answers
- **Evaluation Mode**: Test system performance

### Example Usage
```python
from src.config import Config
from main import initialize_rag_system

# Initialize system
rag_chain, _ = initialize_rag_system()

# Ask a question
response = rag_chain.query("What is LangChain?")

# Access the answer
print(response['result'])

# See source documents
for doc in response['source_documents']:
    print(doc.page_content)
```

## ğŸ“‚ Project Structure
```
langchain-rag-project/
â”œâ”€â”€ data/                    # Document storage
â”‚   â””â”€â”€ sample_docs/         # Your text documents go here
â”œâ”€â”€ vectorstore/             # Vector database (auto-created)
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”œâ”€â”€ data_loader.py       # Document loading & chunking
â”‚   â”œâ”€â”€ embeddings_manager.py# Embedding generation
â”‚   â”œâ”€â”€ vectorstore_manager.py# Vector database management
â”‚   â”œâ”€â”€ retriever_manager.py # Retrieval logic
â”‚   â”œâ”€â”€ llm_manager.py       # LLM integration
â”‚   â”œâ”€â”€ rag_chain.py         # Main RAG pipeline
â”‚   â””â”€â”€ evaluator.py         # Performance evaluation
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

Edit `src/config.py` to customize:

- **LLM Model**: Change to different Groq models
- **Chunk Size**: Adjust document splitting (default: 500 chars)
- **Top-K Retrieval**: Number of documents to retrieve (default: 3)
- **Temperature**: LLM creativity (default: 0.1 for factual)

## ğŸ“Š Evaluation

Run evaluation mode to measure:
- Retrieval quality (speed, relevance)
- Answer quality (length, keyword matching)
- Context relevance (are retrieved docs useful?)
```bash
python main.py
# Select option 3 for evaluation
```

## ğŸ†“ Free Resources Used

1. **Groq API**: Free fast LLM inference
   - Sign up: https://console.groq.com/
   - No credit card required

2. **Sentence Transformers**: Free local embeddings
   - No API needed
   - Runs on your machine

3. **ChromaDB**: Free local vector database
   - No cloud, no costs
   - Persistent storage

## ğŸ› Troubleshooting

### "GROQ_API_KEY not found"
- Make sure you created `.env` file
- Add your API key: `GROQ_API_KEY=your_key_here`

### "No documents found"
- Add .txt files to `data/sample_docs/`
- Sample documents are included

### Slow performance
- First run downloads embedding model (one-time, ~80MB)
- Subsequent runs are much faster

### Import errors
- Make sure virtual environment is activated
- Reinstall: `pip install -r requirements.txt --upgrade`

## ğŸ“š Learning Resources

- LangChain Docs: https://python.langchain.com/
- Groq Documentation: https://console.groq.com/docs
- ChromaDB Guide: https://docs.trychroma.com/
- RAG Explanation: See included sample documents!

## ğŸ¤ Contributing

This is a learning project! Feel free to:
- Add new features
- Improve evaluation metrics
- Try different models
- Share your learnings

## ğŸ“„ License

MIT License - Feel free to use for learning and projects!

## ğŸ“ What You'll Learn

By studying this project, you'll understand:
- How RAG systems work end-to-end
- LangChain's abstractions and components
- Vector databases and semantic search
- Prompt engineering for better answers
- Evaluation and system improvement
- Production-ready code structure

Happy learning! ğŸš€